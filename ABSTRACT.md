The **AI4Agriculture Grape Dataset** consists of 250 images captured within a vineyard located in Ribera de Duero, featuring grapevines of the Tempranillo variety. These images are annotated using bounding boxes. The primary objective of this dataset is to offer both images and corresponding annotations to facilitate the training and validation of object detection models. These models can find practical application in viticulture, enabling tasks such as yield estimation, fruit counting, and field robotics.

The image collection contains twelve distinct parcels, with each parcel further divided into six defined areas. Within each area, multiple rows of grapevines are present. To ensure variety and coverage, four picture samples are taken for each row of grapevines, with two samples from each side. Importantly, these samples are selected from non-contiguous grapevines, ensuring that the images do not overlap.

The authors have focused on applying AI-based techniques in agriculture, utilizing the platform developed within the project. The AI4Agriculture pilot, situated in the Ribera del Duero wine region in Spain, has three main objectives: estimating grape quantities in vineyards, evaluating the final product's quality, and predicting yields. To achieve these objectives, diverse data sources, including drones, mobile cameras, and satellite imagery, are being collected. The system includes a component that processes mobile camera images to identify grapes and estimate their quantities using Deep Learning techniques. Due to the time-intensive nature of labeling, a multi-actor approach has been adopted to expedite the process, although this approach may introduce subjective bias due to various perspectives involved.

To accommodate the multi-labeler approach, the authors conducted an introductory training session to gauge the average time required for labeling a single image and to address challenges inherent to image characteristics. Six labelers were tasked with annotating 45 images, identifying all grape clusters within each image. For each image, an .xml file was generated following the PascalVOC format, documenting all labeled items.

Initially, specific study areas were defined within two different vineyards, spanning multiple rows of grapevines. These areas were chosen considering the pixel dimensions captured by Sentinel satellites (typically 20x20 square meters per pixel) to enable future assessment of plant vigor using satellite images. A total of 403 plants were photographed using a mobile app: 363 from both sides and 40 from a single side. Each side's capture involved three different pictures, taken from the left angle, right angle, and the frontal perspective, resulting in a total of 2,298 images. The photos were taken using Xiaomi Redmi 8 (4032x3024 resolution), Xiaomi Mi A3 (3000x4000 resolution), and Xiaomi Redmi 9 (3264x2448 resolution) smartphones.

However, certain images presented challenges during the labeling process, including issues such as reflections caused by sunlight, clusters of grapes partially concealed by leaves, obstruction by other objects like irrigation pipes, similarity in color and direction to tree trunks, presence of dead grapes on the ground, and grapes from the plants located behind the analyzed plant. Considering the labeling times determined during the introductory training session, a subset of 459 images (from the original 2,298) was selected, specifically those captured from the frontal perspective while excluding images taken from the left and right angles. This selection aimed to eliminate redundant images of the same side of each plant and images with angles revealing the plants and grapes situated behind the plant under analysis. The subsequent labeling session was organized for eight labelers.